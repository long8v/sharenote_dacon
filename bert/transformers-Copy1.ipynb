{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT embedding loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_files = sorted(glob('../bert_file/*.pt'))\n",
    "pt_files_index = [int(pt.split('_')[-1].split('.')[0]) for pt in pt_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17743"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " grad_fn=<BinaryCrossEntropyBackward>),tensor(23.0769, grad_fn=<BinaryCrossEntropyBackward>)\n",
    "tensor(17.6471, grad_fn=<BinaryCrossEntropyBackward>),tensor(17.6471, grad_fn=<BinaryCrossEntropyBackward>)\n",
    "tensor(8.3333, grad_fn=<BinaryCrossEntropyBackward>),tensor(8.3333, grad_fn=<BinaryCrossEntropyBackward>)\n",
    "tensor(15., grad_fn=<BinaryCrossEntropyBackward>),tensor(15., grad_fn=<BinaryCrossEntropyBackward>)\n",
    "torch.Size([1, 24, 768]) torch.Size([1, 24, 1]) torch.Size([4, 6, 1])\n",
    "tensor(23.0769, grad_fn=<BinaryCrossEntropyBackward>),tensor(23.0769, grad_fn=<BinaryCrossEntropyBackward>)\n",
    "tensor(17.6471, grad_fn=<BinaryCrossEntropyBackward>),tensor(17.6471, grad_fn=<BinaryCrossEntropyBackward>)\n",
    "tensor(8.3333, grad_fn=<BinaryCrossEntropyBackwlen(pt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../bert_file/doc_11926.pt\n",
      "../bert_file/doc_17742.pt\n"
     ]
    }
   ],
   "source": [
    "for pt in pt_files:\n",
    "    try:\n",
    "        torch.load(pt)\n",
    "    except:\n",
    "        print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = [torch.load(pt) for pt in pt_files\n",
    "          if pt not in ['../bert_file/doc_11926.pt', '../bert_file/doc_17742.pt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../file/train.jsonl') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = [data[index] for index in pt_files_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sample = [torch.Tensor([1 if _ in data['extractive'] else 0 \n",
    "                            for _ in range(len(data['article_original']))]) \n",
    "                for idx, data in enumerate(data_sample)\n",
    "               if idx not in [11926, 17742]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train-valid split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformerDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, transform_x=None, transform_y=None):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_x = self.data_x[idx]\n",
    "        sample_y = self.data_y[idx]\n",
    "        return sample_x, sample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n",
    "    return xx_pad, yy_pad, x_lens, y_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors = collate_fn_padd(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = transformerDataset(tensors, label_sample)\n",
    "dl = DataLoader(ds, batch_size=4, collate_fn=pad_collate, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dl:\n",
    "    if d[0].shape[0] == 4:\n",
    "        pass\n",
    "    else:\n",
    "        print(d[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT_EMBEDDING_DIM = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_layer = TransformerEncoderLayer(d_model=BERT_EMBEDDING_DIM, nhead=2, dim_feedforward=128, dropout=0.5)\n",
    "# transformer_encoder = TransformerEncoder(encoder_layer, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear = nn.Linear(in_features=768, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors[0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans_output = transformer_encoder(tensors[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = linear(trans_output)\n",
    "# sigmoid = nn.Sigmoid()\n",
    "# output = sigmoid(output)\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = torch.Tensor(label_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion(output, target.view(1,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    # positional encoding layer 따로 정의 \n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model) # positonal encoding\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # 짝수는 sin 함수 적용\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # 홀수는 cos 함수 적용\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ninp, nhead, nhid, n_class, dropout=0.5):\n",
    "        # ntoken : number of sentence\n",
    "        # ninp : the number of expected features in the input\n",
    "        # nhead : the number of heads in multi-head attention model \n",
    "        # nhid : the dimension of the feedforward network model \n",
    "        # nlayers : the number of class\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, n_class)\n",
    "        self.ninp = ninp\n",
    "        self.lstm = nn.LSTM(ninp, ninp)\n",
    "        self.linear = nn.Linear(in_features=ninp, out_features=n_class)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        # encoder의 nn.Embedding의 레이어 초기화\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = src * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.linear(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "device = 'cuda'\n",
    "model = TransformerModel(ninp=768, nhead=64, nhid=4096, n_class=1).to(device)\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "for epoch in range(300):\n",
    "    i = 0 \n",
    "    for batch in dl:\n",
    "        tensor = batch[0].to(device)\n",
    "        label = batch[1].to(device)\n",
    "        try:\n",
    "            label = label.view(4, -1, 1)\n",
    "            output = model(tensor)\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            i += 1\n",
    "            if i % 1000 == 0 :\n",
    "                loss_list.append(loss)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(tensor.shape, output.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "long36v",
   "language": "python",
   "name": "long36v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
